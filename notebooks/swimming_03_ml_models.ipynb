{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Swimming — ML Models (Reg + Class)\n",
    "# =====================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, r2_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "\n",
    "# -------------------------\n",
    "# 0) Load cleaned dataset\n",
    "# -------------------------\n",
    "csv_path = \"/Users/amlim/triathlon-performance/data/cleaned_swimming.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "required = [\n",
    "    \"date\", \"start_time\", \"time_of_day\", \"indoor_outdoor\",\n",
    "    \"distance_m\", \"duration_min\", \"pace_min_per_100m\",\n",
    "    \"high_effectiveness_swim\"\n",
    "]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in cleaned_swimming.csv: {missing}\")\n",
    "\n",
    "# Normalize categoricals\n",
    "df[\"time_of_day\"] = df[\"time_of_day\"].astype(str).str.strip().str.title()\n",
    "df[\"indoor_outdoor\"] = (\n",
    "    df[\"indoor_outdoor\"].astype(str).str.strip().str.lower()\n",
    "    .replace({\"indoors\":\"indoor\",\"outdoors\":\"outdoor\"})\n",
    ")\n",
    "\n",
    "# -------------------------------------\n",
    "# 1) Feature engineering (for regression)\n",
    "# -------------------------------------\n",
    "# Guard against division by zero/NaN\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    # baseline pace computed from distance/time (min/100m)\n",
    "    df[\"pace_baseline_min_per_100m\"] = df[\"duration_min\"] / (df[\"distance_m\"] / 100.0)\n",
    "\n",
    "df.loc[~np.isfinite(df[\"pace_baseline_min_per_100m\"]), \"pace_baseline_min_per_100m\"] = np.nan\n",
    "\n",
    "# Stabilize distance scaling\n",
    "df[\"log_distance_m\"] = np.log1p(df[\"distance_m\"])\n",
    "\n",
    "# Distance bins (short/med/long)\n",
    "bins = [-np.inf, 800, 1500, 2500, 4000, np.inf]\n",
    "labels = [\"<=800m\", \"800-1500m\", \"1500-2500m\", \"2500-4000m\", \">4000m\"]\n",
    "df[\"distance_bin\"] = pd.cut(df[\"distance_m\"], bins=bins, labels=labels)\n",
    "\n",
    "# -------------------------------------\n",
    "# 2) One-hot encode categoricals (safe)\n",
    "# -------------------------------------\n",
    "cat_cols = []\n",
    "if df[\"time_of_day\"].nunique() > 1:\n",
    "    cat_cols.append(\"time_of_day\")\n",
    "if df[\"indoor_outdoor\"].nunique() > 1:\n",
    "    cat_cols.append(\"indoor_outdoor\")\n",
    "if df[\"distance_bin\"].notna().any() and df[\"distance_bin\"].nunique() > 1:\n",
    "    cat_cols.append(\"distance_bin\")\n",
    "\n",
    "df_ml = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# -------------------------------------\n",
    "# 3) Build feature matrices\n",
    "# -------------------------------------\n",
    "reg_target = \"pace_min_per_100m\"                 # lower is better\n",
    "clf_target = \"high_effectiveness_swim\"           # 1 = top 25% fastest\n",
    "\n",
    "# numeric base features (add more later if you collect them)\n",
    "base_feats = [\n",
    "    \"distance_m\", \"duration_min\",\n",
    "    \"pace_baseline_min_per_100m\", \"log_distance_m\"\n",
    "]\n",
    "base_feats = [c for c in base_feats if c in df_ml.columns]\n",
    "\n",
    "# collect created dummies\n",
    "dummy_feats = [c for c in df_ml.columns if c.startswith(\"time_of_day_\")\n",
    "                                      or c.startswith(\"indoor_outdoor_\")\n",
    "                                      or c.startswith(\"distance_bin_\")]\n",
    "\n",
    "X_cols = base_feats + dummy_feats\n",
    "if not X_cols:\n",
    "    raise ValueError(\"No feature columns found. Check your cleaned CSV and one-hot encoding.\")\n",
    "\n",
    "X = df_ml[X_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "y_reg = df_ml[reg_target]\n",
    "y_clf = df_ml[clf_target].astype(int)\n",
    "\n",
    "mask = X.notna().all(axis=1) & y_reg.notna() & y_clf.notna()\n",
    "X, y_reg, y_clf = X.loc[mask], y_reg.loc[mask], y_clf.loc[mask]\n",
    "\n",
    "# Train/test splits (keep classification stratified)\n",
    "X_tr, X_te, y_tr_reg, y_te_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "X_tr_c, X_te_c, y_tr_clf, y_te_clf = train_test_split(X, y_clf, test_size=0.2, random_state=42, stratify=y_clf)\n",
    "\n",
    "# -------------------------------------\n",
    "# 4) Scale features (fit on train only)\n",
    "# -------------------------------------\n",
    "reg_scaler = StandardScaler()\n",
    "X_tr_s = reg_scaler.fit_transform(X_tr)\n",
    "X_te_s = reg_scaler.transform(X_te)\n",
    "\n",
    "clf_scaler = StandardScaler()\n",
    "X_tr_c_s = clf_scaler.fit_transform(X_tr_c)\n",
    "X_te_c_s = clf_scaler.transform(X_te_c)\n",
    "\n",
    "# -------------------------------------\n",
    "# 5A) TensorFlow Regression (predict pace_min_per_100m)\n",
    "# -------------------------------------\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "reg_model = Sequential([\n",
    "    layers.Input(shape=(X_tr_s.shape[1],)),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "reg_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "early = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "hist_reg = reg_model.fit(\n",
    "    X_tr_s, y_tr_reg,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    verbose=0,\n",
    "    callbacks=[early]\n",
    ")\n",
    "\n",
    "yhat_reg = reg_model.predict(X_te_s).ravel()\n",
    "print(\"\\n=== Swimming Regression (Pace min/100m) ===\")\n",
    "print(\"MAE:\", round(mean_absolute_error(y_te_reg, yhat_reg), 4))\n",
    "print(\"R² :\", round(r2_score(y_te_reg, yhat_reg), 4))\n",
    "\n",
    "# -------------------------------------\n",
    "# 5B) TensorFlow Classification (high effectiveness)\n",
    "# -------------------------------------\n",
    "classes = np.unique(y_tr_clf)\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_tr_clf)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "\n",
    "clf_model = Sequential([\n",
    "    layers.Input(shape=(X_tr_c_s.shape[1],)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "clf_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_c = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "hist_clf = clf_model.fit(\n",
    "    X_tr_c_s, y_tr_clf,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=16,\n",
    "    verbose=0,\n",
    "    callbacks=[early_c],\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "probs = clf_model.predict(X_te_c_s).ravel()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Swimming Classification (High Effectiveness) ===\")\n",
    "print(classification_report(y_te_clf, preds, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_te_clf, preds))\n",
    "try:\n",
    "    print(\"ROC AUC:\", round(roc_auc_score(y_te_clf, probs), 4))\n",
    "except ValueError:\n",
    "    print(\"ROC AUC: not defined (only one class present in y_true).\")\n",
    "\n",
    "# -------------------------------------\n",
    "# 6) (Optional) Threshold tuning helpers\n",
    "# -------------------------------------\n",
    "try:\n",
    "    from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fpr, tpr, thr = roc_curve(y_te_clf, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC — Swim Effectiveness\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    prec, rec, pr_thr = precision_recall_curve(y_te_clf, probs)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(rec, prec)\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"PR Curve — Swim Effectiveness\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Example alt threshold\n",
    "    opt_thresh = 0.65\n",
    "    preds_alt = (probs >= opt_thresh).astype(int)\n",
    "    print(f\"\\nClassification report @ threshold {opt_thresh}\")\n",
    "    print(classification_report(y_te_clf, preds_alt, digits=3))\n",
    "except Exception as e:\n",
    "    print(\"Threshold plotting skipped:\", e)\n",
    "\n",
    "# -------------------------------------\n",
    "# 7) Save artifacts (models + scalers)\n",
    "# -------------------------------------\n",
    "out_dir = \"/Users/amlim/triathlon-performance/results/models\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "reg_model_path = os.path.join(out_dir, \"swim_pace_reg_v1.keras\")\n",
    "clf_model_path = os.path.join(out_dir, \"swim_effectiveness_clf_v1.keras\")\n",
    "reg_model.save(reg_model_path)\n",
    "clf_model.save(clf_model_path)\n",
    "\n",
    "joblib.dump(reg_scaler, os.path.join(out_dir, \"swim_reg_scaler_v1.joblib\"))\n",
    "joblib.dump(clf_scaler, os.path.join(out_dir, \"swim_clf_scaler_v1.joblib\"))\n",
    "\n",
    "print(f\"\\nSaved models:\\n  {reg_model_path}\\n  {clf_model_path}\")\n",
    "print(f\"Saved scalers in {out_dir}\")\n",
    "print(\"\\nFeature columns used:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cycling)",
   "language": "python",
   "name": "cycling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
